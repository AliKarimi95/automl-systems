{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzp80rpDYC87"
      },
      "source": [
        "# Install requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKrGH5IoX6wH"
      },
      "outputs": [],
      "source": [
        "!pip install autokeras\n",
        "\n",
        "!pip install autogluon\n",
        "!pip install mxnet>=1.9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeYidPISfvip"
      },
      "source": [
        "# Download and read dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gQ_WL4GY3iX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import datetime\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import autokeras as ak\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# pd.options.plotting.backend = 'plotly'\n",
        "pd.options.plotting.backend = 'matplotlib'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Av_Fucusgp4O"
      },
      "source": [
        "## Weather dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxcDYPetZEtv"
      },
      "outputs": [],
      "source": [
        "def get_weather_dataset():\n",
        "    zip_path = tf.keras.utils.get_file(\n",
        "        origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
        "        fname='jena_climate_2009_2016.csv.zip',\n",
        "        extract=True,\n",
        "        cache_dir='dataset')\n",
        "    csv_path, _ = os.path.splitext(zip_path)\n",
        "    df = pd.read_csv(csv_path)\n",
        "    df['Date Time'] = pd.to_datetime(df['Date Time'], format='%d.%m.%Y %H:%M:%S')\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCFl4dnKgtti"
      },
      "outputs": [],
      "source": [
        "weather_df = get_weather_dataset()\n",
        "print('dataset size:', len(weather_df))\n",
        "weather_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXWFAgv3g1JY"
      },
      "outputs": [],
      "source": [
        "weather_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSxJOjptOOyq"
      },
      "outputs": [],
      "source": [
        "weather_df.set_index('Date Time', drop=True)['p (mbar)'].plot()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weather_df.set_index('Date Time', drop=True)['T (degC)'].plot()"
      ],
      "metadata": {
        "id": "17rZamYLRp2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weather_df.set_index('Date Time', drop=True)['wv (m/s)'].plot()"
      ],
      "metadata": {
        "id": "mpupsEBWRtZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt = weather_df['Date Time'].sort_values()\n",
        "interval = dt - dt.shift(1)\n",
        "interval.value_counts()"
      ],
      "metadata": {
        "id": "yo_vHvJNACo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXGoeX7thFQk"
      },
      "source": [
        "## Air quality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oj2GqhrLgM-V"
      },
      "outputs": [],
      "source": [
        "def get_air_quality_dataset():\n",
        "    zip_path = tf.keras.utils.get_file(\n",
        "        fname=\"AirQualityUCI.csv.zip\",\n",
        "        origin=\"https://archive.ics.uci.edu/ml/machine-learning-databases/00360/AirQualityUCI.zip\",\n",
        "        extract=True,\n",
        "        cache_dir='dataset'\n",
        "    )\n",
        "    csv_path, _ = os.path.splitext(zip_path)\n",
        "    dataset = pd.read_csv(csv_path, sep=\";\", parse_dates=[['Date', 'Time']])\n",
        "    dataset = dataset[dataset.columns[:-2]]\n",
        "    dataset = dataset.dropna()\n",
        "    dataset = dataset.replace(\",\", \".\", regex=True)\n",
        "    dataset['Date_Time'] = pd.to_datetime(dataset['Date_Time'], format='%d/%m/%Y %H.%M.%S')\n",
        "    numeric_col = dataset.columns[1:]\n",
        "    dataset[numeric_col] = dataset[numeric_col].astype(float)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFwk6cxEZIr5"
      },
      "outputs": [],
      "source": [
        "air_df = get_air_quality_dataset()\n",
        "print('dataset size:', len(air_df))\n",
        "air_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1LxXjQYgJAT"
      },
      "outputs": [],
      "source": [
        "air_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "air_df.set_index('Date_Time', drop=True)['AH'].plot(backend='plotly')"
      ],
      "metadata": {
        "id": "0Wh5Gov3R__-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt = air_df['Date_Time'].sort_values()\n",
        "interval = dt - dt.shift(1)\n",
        "interval.value_counts()"
      ],
      "metadata": {
        "id": "um0XmC1JgjOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9A2JZDp13Qt"
      },
      "source": [
        "## Covid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9T-opEq1kVe"
      },
      "outputs": [],
      "source": [
        "def get_covid_dataset():\n",
        "    df = pd.read_csv(\n",
        "        \"https://autogluon.s3-us-west-2.amazonaws.com/datasets/CovidTimeSeries/train.csv\",\n",
        "        parse_dates=[\"Date\"],\n",
        "    )\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5Hmzeg319me"
      },
      "outputs": [],
      "source": [
        "covid_df = get_covid_dataset()\n",
        "print('dataset count:', len(covid_df))\n",
        "covid_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FUW19Sv2IOC"
      },
      "outputs": [],
      "source": [
        "covid_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_cW40S_5Om7"
      },
      "outputs": [],
      "source": [
        "covid_df['Date'].plot(kind='hist', backend='plotly')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crYjbhG45m_3"
      },
      "outputs": [],
      "source": [
        "covid_df['name'].plot(kind='hist', backend='plotly')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define datasets"
      ],
      "metadata": {
        "id": "pb4MGfdjeetx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.timeseries import TimeSeriesDataFrame\n",
        "\n",
        "\n",
        "class Dataset:\n",
        "    def __init__(self, name, df, time_col, target_col, prediction_length, item_id_col=None):\n",
        "        self.name = name\n",
        "        self.df = df\n",
        "        self.initial_time_col = time_col\n",
        "        self.initial_item_id = item_id_col\n",
        "        self.target_col = target_col\n",
        "        self.prediction_length = prediction_length\n",
        "\n",
        "        self.time_col = 'timestamp'\n",
        "        self.item_id = 'item_id'\n",
        "\n",
        "    def split(self):\n",
        "        data = self.df.copy()\n",
        "        if self.initial_item_id is None:\n",
        "            data[self.item_id] = 0\n",
        "        else:\n",
        "            data = data.rename({ self.initial_item_id : self.item_id }, axis=1)\n",
        "\n",
        "        data = TimeSeriesDataFrame.from_data_frame(\n",
        "            data,\n",
        "            id_column=self.item_id,\n",
        "            timestamp_column=self.initial_time_col\n",
        "        )\n",
        "\n",
        "        test_data = data.copy()  # the full data set\n",
        "        # the data set with the last prediction_length time steps included, i.e., akin to `a[:-5]`\n",
        "        train_data = data.slice_by_timestep(slice(None, -self.prediction_length))\n",
        "\n",
        "        os.makedirs('splits', exist_ok=True)\n",
        "        test_data.to_csv(os.path.join('splits', f'{self.name}_test.csv'))\n",
        "        train_data.to_csv(os.path.join('splits', f'{self.name}_train.csv'))\n",
        "\n",
        "    def read_split(self, split):\n",
        "        df = pd.read_csv(os.path.join('splits', f'{self.name}_{split}.csv'))\n",
        "        df[self.time_col] = pd.to_datetime(df[self.time_col])\n",
        "        return df\n"
      ],
      "metadata": {
        "id": "uZpTSRfaedBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = [\n",
        "    # Dataset('weather_hour', weather_df, 'Date Time', 'T (degC)', prediction_length=12),\n",
        "    Dataset('air_quality_day', air_df, 'Date_Time', 'AH', prediction_length=24),\n",
        "    Dataset('air_quality_week', air_df, 'Date_Time', 'AH', prediction_length=24*7),\n",
        "    Dataset('covid_3day', covid_df, 'Date', 'ConfirmedCases', prediction_length=3, item_id_col='name'),\n",
        "    Dataset('covid_week', covid_df, 'Date', 'ConfirmedCases', prediction_length=7, item_id_col='name'),\n",
        "]"
      ],
      "metadata": {
        "id": "IVobVoj5o0IS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for d in datasets:\n",
        "    print(f'splitting {d.name}')\n",
        "    d.split()"
      ],
      "metadata": {
        "id": "S1QruL_3qGBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check"
      ],
      "metadata": {
        "id": "XrBKOdLh1UDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!head covid_week_test.csv"
      ],
      "metadata": {
        "id": "2lWt9sG_1X7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "air_df.tail()"
      ],
      "metadata": {
        "id": "pQQOFgBN6g6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tail air_quality_day_test.csv"
      ],
      "metadata": {
        "id": "mVVl8FtosmA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tail air_quality_day_train.csv"
      ],
      "metadata": {
        "id": "o-aDbmP56aJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AutoML systems"
      ],
      "metadata": {
        "id": "Pby6RRyVqQnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeSeriesAutoMLSystem:\n",
        "    def set_dataset(self, dataset):\n",
        "        pass\n",
        "        \n",
        "    def fit(self, time_budget):\n",
        "        pass\n",
        "    \n",
        "    def predict_test(self):\n",
        "        pass"
      ],
      "metadata": {
        "id": "WIfC0vxqqQDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhGX4CpY2Xc5"
      },
      "source": [
        "## Auto-gluon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmxUGx5B6AYV"
      },
      "outputs": [],
      "source": [
        "from autogluon.timeseries import TimeSeriesPredictor, TimeSeriesDataFrame\n",
        "\n",
        "\n",
        "class AutoGluonTSSystem(TimeSeriesAutoMLSystem):\n",
        "    def set_dataset(self, dataset: Dataset):\n",
        "        self.dataset = dataset\n",
        "        train_df = dataset.read_split('train')\n",
        "        test_df = dataset.read_split('test')\n",
        "\n",
        "        self.train = TimeSeriesDataFrame.from_data_frame(\n",
        "            train_df,\n",
        "            id_column=self.dataset.item_id,\n",
        "            timestamp_column=self.dataset.time_col\n",
        "        )\n",
        "        self.test = TimeSeriesDataFrame.from_data_frame(\n",
        "            test_df,\n",
        "            id_column=self.dataset.item_id,\n",
        "            timestamp_column=self.dataset.time_col\n",
        "        )\n",
        "        \n",
        "    def fit(self, time_budget: int):\n",
        "        self.aml = TimeSeriesPredictor(\n",
        "            path=os.path.join('outputs', f'autogluon-{time_budget}', self.dataset.name),\n",
        "            target=self.dataset.target_col,\n",
        "            prediction_length=self.dataset.prediction_length,\n",
        "            eval_metric='MAPE'\n",
        "        )\n",
        "        self.aml.fit(\n",
        "            train_data=self.train,\n",
        "            presets='medium_quality',\n",
        "            time_limit=time_budget\n",
        "        )\n",
        "    \n",
        "    def predict_test(self):\n",
        "        predictions = self.aml.predict(self.train)\n",
        "        return predictions['mean']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aml = AutoGluonTSSystem()\n",
        "aml.set_dataset(datasets[0])\n",
        "aml.fit(time_budget=60)\n",
        "p = aml.predict_test()"
      ],
      "metadata": {
        "id": "YIdXhBNttqeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aml.aml.leaderboard(aml.test, silent=True)"
      ],
      "metadata": {
        "id": "oS97v7jLBp8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aml.predict_test()"
      ],
      "metadata": {
        "id": "AaLOJ4I60fZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Auto-keras"
      ],
      "metadata": {
        "id": "z-IHjrfk2fpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import autokeras as ak\n",
        "\n",
        "\n",
        "class AutoKerasTSAutoML(TimeSeriesAutoMLSystem):\n",
        "    def set_dataset(self, dataset):\n",
        "        self.dataset = dataset\n",
        "        self.train_df = self.dataset.read_split('train').sort_values(dataset.time_col)\n",
        "        self.test_df = self.dataset.read_split('test').sort_values(dataset.time_col)\n",
        "\n",
        "        n_items = len(self.train_df[self.dataset.item_id].unique())\n",
        "        if n_items > 1:\n",
        "            raise ValueError(\"Can't make traning on multiple items datasets\")\n",
        "\n",
        "        self._feature_cols = list(self.train_df.columns)\n",
        "        self._feature_cols.remove(self.dataset.target_col)\n",
        "        self._feature_cols.remove(self.dataset.item_id)\n",
        "        self._feature_cols.remove(self.dataset.time_col)\n",
        "        \n",
        "    def fit(self, time_budget):\n",
        "        x, y = self.train_df[self._feature_cols], self.train_df[[self.dataset.target_col]]\n",
        "        start_time = time.time()        \n",
        "        elapsed_time = 0\n",
        "        lb = d.prediction_length\n",
        "        bs = 64\n",
        "        if lb > bs:\n",
        "            c = int(lb / bs)\n",
        "            bs = int(lb / c)\n",
        "        else:\n",
        "            bs = lb\n",
        "        \n",
        "        while elapsed_time < time_budget:\n",
        "            print(f'start new trial ...')\n",
        "            self.aml = ak.TimeseriesForecaster(\n",
        "                lookback=lb,\n",
        "                predict_from=1,\n",
        "                predict_until=lb,\n",
        "                max_trials=1,\n",
        "                directory=os.path.join('outputs', f'autokeras_{time_budget}'),\n",
        "                project_name=d.name,\n",
        "                # metrics='mean_absolute_percentage_error',\n",
        "                overwrite=False\n",
        "            )\n",
        "            self.aml.fit(x, y, verbose=True, batch_size=bs, epochs=10)\n",
        "            elapsed_time = int(time.time() - start_time)\n",
        "            print('elapsed time:', elapsed_time)\n",
        "    \n",
        "    def predict_test(self):\n",
        "        x = self.test_df[self._feature_cols]\n",
        "        p = self.aml.predict(x)\n",
        "        return p"
      ],
      "metadata": {
        "id": "2PtZJCCYdFBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = datasets[0]\n",
        "\n",
        "akml = AutoKerasTSAutoML()\n",
        "akml.set_dataset(d)\n",
        "akml.fit(60)"
      ],
      "metadata": {
        "id": "Hqfu3gt02e6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "self = akml\n",
        "autokeras_aml = self.aml\n",
        "\n",
        "x = self.train_df[self._feature_cols]\n",
        "x = autokeras_aml.read_for_predict(x)\n",
        "x\n",
        "# p = self.aml.predict(x, y=self.dataset.target_col)\n",
        "# p"
      ],
      "metadata": {
        "id": "rnsRubiukmrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = super(type(autokeras_aml), autokeras_aml).predict(x=x)"
      ],
      "metadata": {
        "id": "yggwMqiYGFkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "A7mumWg6GuMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Benchmarking"
      ],
      "metadata": {
        "id": "JGCfaMqN2ikr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "systems_cls = [AutoGluonTSSystem]\n",
        "time_budgets = [5*60, 15*60]   # [5*60, 20*60]\n",
        "selected_datasets = datasets"
      ],
      "metadata": {
        "id": "2FddqdJd2mai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "\n",
        "\n",
        "def calculate_metrics(predictions, dataset):\n",
        "    test_df = dataset.read_split('test')\n",
        "    test_df = test_df.set_index([dataset.item_id, dataset.time_col], drop=True)\n",
        "    labels = test_df.loc[predictions.index][dataset.target_col]\n",
        "\n",
        "    metrics = {\n",
        "        'MAPE': mean_absolute_percentage_error(labels, predictions),\n",
        "    }\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "o2nYCeZx3A6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run(system_cls, time_budget, dataset):\n",
        "    system_name = system_cls.__name__\n",
        "    result = {\n",
        "        'system': system_name,\n",
        "        'budget': time_budget,\n",
        "        'dataset': dataset.name,\n",
        "        'status': 'failed'\n",
        "    }\n",
        "    \n",
        "    try:\n",
        "        print(f'Start run:\\n\\tSystem: {system_name}\\n\\tBudget: {time_budget}\\n\\tDataset: {dataset.name}\\n')\n",
        "        print('start loading system ...')\n",
        "        t = time.time()\n",
        "        aml = system_cls()\n",
        "        aml.set_dataset(dataset)\n",
        "        result['load_time'] = time.time() - t\n",
        "\n",
        "        print('start training ...')\n",
        "        t = time.time()\n",
        "        aml.fit(time_budget)\n",
        "        result['train_time'] = time.time() - t\n",
        "\n",
        "        print('start predicting ...')\n",
        "        t = time.time()\n",
        "        predictions = aml.predict_test()\n",
        "        result['inference_time'] = time.time() - t\n",
        "        \n",
        "        print('caculating metrics ...')\n",
        "        metrics = calculate_metrics(predictions, dataset)\n",
        "        for m in metrics:\n",
        "            result[f'metric_{m}'] = metrics[m]\n",
        "\n",
        "        result['status'] = 'success'\n",
        "        \n",
        "    except Exception as e:\n",
        "        print('EXCEPTION:', e)\n",
        "        result['exception'] = str(e)\n",
        "    \n",
        "    print(result)\n",
        "    return result"
      ],
      "metadata": {
        "id": "0N_A7gfR8e0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_results = []\n",
        "\n",
        "for b in time_budgets:\n",
        "    for dataset in selected_datasets:\n",
        "        for sys in systems_cls:\n",
        "            r = run(sys, b, dataset)\n",
        "            all_results.append(r)\n",
        "            pd.DataFrame(all_results).to_csv('results.csv', index=False)"
      ],
      "metadata": {
        "id": "xcbSZyyM899I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "MdC50PoeJ9yR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.read_csv('results.csv')\n",
        "results_df"
      ],
      "metadata": {
        "id": "hjzNPVlYJ9Wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Draft"
      ],
      "metadata": {
        "id": "aOq6j9wJ1--N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Air quality"
      ],
      "metadata": {
        "id": "Pwr0xVNkS2dA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eiDK5XJ-SL2"
      },
      "outputs": [],
      "source": [
        "air_train_data = TimeSeriesDataFrame.from_data_frame(\n",
        "    air_df,\n",
        "    timestamp_column=\"Date_Time\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4O06Bv7_EFZ"
      },
      "outputs": [],
      "source": [
        "air_df['item_id'] = 0\n",
        "air_train_data = TimeSeriesDataFrame.from_data_frame(\n",
        "    air_df,\n",
        "    timestamp_column=\"Date_Time\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osdfSQ24AIiB"
      },
      "outputs": [],
      "source": [
        "prediction_length = 24 * 7\n",
        "\n",
        "air_test_data = air_train_data.copy()  # the full data set\n",
        "\n",
        "# the data set with the last prediction_length time steps included, i.e., akin to `a[:-5]`\n",
        "air_train_data = air_train_data.slice_by_timestep(slice(None, -prediction_length))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(air_test_data) - len(air_train_data)"
      ],
      "metadata": {
        "id": "4I5TDydPQLm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_G00kOzEEEFU"
      },
      "outputs": [],
      "source": [
        "air_predictor = TimeSeriesPredictor(\n",
        "    path=\"autogluon-air-quality-test\",\n",
        "    target=\"AH\",\n",
        "    prediction_length=prediction_length,\n",
        "    eval_metric=\"MAPE\",\n",
        ")\n",
        "air_predictor.fit(\n",
        "    train_data=air_train_data,\n",
        "    presets=\"low_quality\",\n",
        "    time_limit=300\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "air_predictor.leaderboard(air_test_data, silent=True)"
      ],
      "metadata": {
        "id": "mEdtkC1uQvT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = air_predictor.predict(air_test_data)\n",
        "predictions"
      ],
      "metadata": {
        "id": "OHDVPObSRLbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(predictions)"
      ],
      "metadata": {
        "id": "ssln7FlPRY1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m92CSyzK-w_6"
      },
      "source": [
        "## Covid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAobm2q_6EAV"
      },
      "outputs": [],
      "source": [
        "train_data = TimeSeriesDataFrame.from_data_frame(\n",
        "    covid_df,\n",
        "    id_column=\"name\",\n",
        "    timestamp_column=\"Date\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8p22GjsJ6gnJ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 3))\n",
        "for country in [\"United Kingdom_\", \"Germany_\"]:\n",
        "    plt.plot(train_data.loc[country], label=country)\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2rFn70-8ni3"
      },
      "outputs": [],
      "source": [
        "prediction_length = 7\n",
        "\n",
        "test_data = train_data.copy()  # the full data set\n",
        "\n",
        "# the data set with the last prediction_length time steps included, i.e., akin to `a[:-5]`\n",
        "train_data = train_data.slice_by_timestep(slice(None, -prediction_length))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSdUIPG60_0y"
      },
      "outputs": [],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loTSfoZF8--q"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 3))\n",
        "plt.plot(test_data.loc[\"Germany_\"], label=\"test\")\n",
        "plt.plot(train_data.loc[\"Germany_\"], label=\"train\")\n",
        "\n",
        "test_range = (\n",
        "    test_data.loc[\"Germany_\"].index.max(),\n",
        "    train_data.loc[\"Germany_\"].index.max(),\n",
        ")\n",
        "\n",
        "plt.fill_betweenx(\n",
        "    y=(0, test_data.loc[\"Germany_\"][\"ConfirmedCases\"].max()),\n",
        "    x1=test_range[0],\n",
        "    x2=test_range[1],\n",
        "    alpha=0.1,\n",
        "    label=\"test forecast horizon\",\n",
        ")\n",
        "\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhuJOZDO9Qj-"
      },
      "outputs": [],
      "source": [
        "prediction_length=7\n",
        "\n",
        "predictor = TimeSeriesPredictor(\n",
        "    path=\"autogluon-covidforecast\",\n",
        "    target=\"ConfirmedCases\",\n",
        "    prediction_length=prediction_length,\n",
        "    eval_metric=\"MAPE\",\n",
        ")\n",
        "predictor.fit(\n",
        "    train_data=train_data,\n",
        "    presets=\"medium_quality\",\n",
        "    time_limit=15*60\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vqvfai-29_b-"
      },
      "outputs": [],
      "source": [
        "predictor.leaderboard(test_data, silent=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3gkj3aBAWvg"
      },
      "outputs": [],
      "source": [
        "predictions = predictor.predict(train_data)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.reset_index()['item_id'].unique()"
      ],
      "metadata": {
        "id": "_EfkjANJaY79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHjuLTsyAQLg"
      },
      "outputs": [],
      "source": [
        "country = 'Afghanistan_'\n",
        "country = 'Iran_'\n",
        "# country = 'France_'\n",
        "# country = 'Germany_'\n",
        "# country = 'Cyprus_'\n",
        "plt.figure(figsize=(20, 3))\n",
        "\n",
        "ytrue = train_data.loc[country][\"ConfirmedCases\"]\n",
        "ypred = predictions.loc[country]\n",
        "\n",
        "# prepend the last value of true range to predicted range for plotting continuity\n",
        "ypred.loc[ytrue.index[-1]] = [ytrue[-1]] * 10\n",
        "ypred = ypred.sort_index()\n",
        "\n",
        "ytrue_test = test_data.loc[country][\"ConfirmedCases\"][-5:]\n",
        "\n",
        "plt.plot(ytrue[-30:], label=\"Training Data\")\n",
        "plt.plot(ypred[\"mean\"], label=\"Mean Forecasts\")\n",
        "plt.plot(ytrue_test, label=\"Actual\")\n",
        "\n",
        "plt.fill_between(\n",
        "    ypred.index, ypred[\"0.1\"], ypred[\"0.9\"], color=\"red\", alpha=0.1\n",
        ")\n",
        "plt.title(f\"COVID Case Forecasts in {country}, compared to actual trajectory\")\n",
        "_ = plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DN_aU8zEWfcX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "pzp80rpDYC87",
        "XrBKOdLh1UDc",
        "Pwr0xVNkS2dA"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}